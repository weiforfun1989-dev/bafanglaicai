# -*- coding: utf-8 -*-
"""
===================================
Truth Social Tracker - Trump å¸–å­è¿½è¸ªå™¨
===================================

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æŠ“å– Trump çš„ Truth Social å¸–å­
2. å­˜å‚¨åˆ°æœ¬åœ°æ•°æ®åº“
3. æ£€æµ‹æ–°å¸–å­å¹¶é€šçŸ¥
4. åˆ†æå¸–å­å†…å®¹ï¼ˆæƒ…æ„Ÿã€å…³é”®è¯ã€è‚¡ç¥¨æåŠï¼‰
5. ä¸è‚¡ç¥¨åˆ†æç³»ç»Ÿé›†æˆ

ä½¿ç”¨æ–¹å¼ï¼š
    python truth_tracker.py                    # è¿è¡Œä¸€æ¬¡æŠ“å–
    python truth_tracker.py --daemon           # å®ˆæŠ¤æ¨¡å¼ï¼ŒæŒç»­ç›‘æ§
    python truth_tracker.py --analyze          # åˆ†æå†å²å¸–å­
"""

import argparse
import json
import logging
import os
import re
import sqlite3
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, asdict
from pathlib import Path

import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¸¸é‡
TRUMP_USERNAME = "realdonaldtrump"
TRUTH_SOCIAL_API = "https://truthsocial.com/api/v1"
DB_PATH = Path(__file__).parent / "data" / "truth_social.db"
DATA_DIR = Path(__file__).parent / "data"

# è‚¡ç¥¨ä»£ç æ­£åˆ™ï¼ˆåŒ¹é… $TSLA æˆ– #TSLA æ ¼å¼ï¼‰
STOCK_PATTERN = re.compile(r'[\$#]([A-Z]{1,5})')


@dataclass
class TruthPost:
    """Truth Social å¸–å­æ•°æ®ç±»"""
    id: str
    created_at: str
    content: str
    url: str
    media_urls: List[str]
    replies_count: int
    reblogs_count: int
    favourites_count: int
    
    # åˆ†æå­—æ®µ
    sentiment_score: float = 0.0  # -1 åˆ° 1
    sentiment_label: str = "neutral"  # positive/negative/neutral
    mentioned_stocks: List[str] = None
    keywords: List[str] = None
    
    def __post_init__(self):
        if self.mentioned_stocks is None:
            self.mentioned_stocks = []
        if self.keywords is None:
            self.keywords = []


class TruthSocialTracker:
    """Truth Social è¿½è¸ªå™¨"""
    
    def __init__(self, db_path: str = None):
        self.db_path = db_path or str(DB_PATH)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        DATA_DIR.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ– SQLite æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS posts (
                id TEXT PRIMARY KEY,
                created_at TEXT,
                content TEXT,
                url TEXT,
                media_urls TEXT,
                replies_count INTEGER,
                reblogs_count INTEGER,
                favourites_count INTEGER,
                sentiment_score REAL,
                sentiment_label TEXT,
                mentioned_stocks TEXT,
                keywords TEXT,
                fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_created_at ON posts(created_at)
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_mentioned_stocks ON posts(mentioned_stocks)
        ''')
        
        conn.commit()
        conn.close()
        logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
    
    def fetch_posts(self, username: str = TRUMP_USERNAME, limit: int = 40) -> List[TruthPost]:
        """
        ä» Truth Social è·å–å¸–å­
        
        ä½¿ç”¨ç¬¬ä¸‰æ–¹ RSS æœåŠ¡æˆ– API
        
        Args:
            username: ç”¨æˆ·å
            limit: è·å–æ•°é‡
            
        Returns:
            å¸–å­åˆ—è¡¨
        """
        posts = []
        
        # å°è¯•å¤šä¸ªæ•°æ®æº
        urls_to_try = [
            # æ–¹æ³•1: ä½¿ç”¨ nitter å®ä¾‹ (Twitter/X é•œåƒï¼Œä½†å¯èƒ½æ”¯æŒ Truth Social)
            # æ–¹æ³•2: ä½¿ç”¨ RSSHub
            f"https://rsshub.app/truthsocial/user/{username}",
            # æ–¹æ³•3: ä½¿ç”¨ trumpstruth.org (ç¬¬ä¸‰æ–¹ RSS)
            f"https://trumpstruth.org/feed",
        ]
        
        for url in urls_to_try:
            try:
                logger.info(f"å°è¯•ä» {url} è·å–...")
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                
                # è§£æ RSS
                import xml.etree.ElementTree as ET
                root = ET.fromstring(response.content)
                
                for item in root.findall('.//item'):
                    try:
                        post_id = item.find('guid').text if item.find('guid') is not None else ""
                        title = item.find('title').text if item.find('title') is not None else ""
                        link = item.find('link').text if item.find('link') is not None else ""
                        pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ""
                        
                        description = item.find('description')
                        content = description.text if description is not None else title
                        
                        post = TruthPost(
                            id=post_id,
                            created_at=pub_date,
                            content=content,
                            url=link,
                            media_urls=[],
                            replies_count=0,
                            reblogs_count=0,
                            favourites_count=0
                        )
                        
                        posts.append(post)
                        
                    except Exception as e:
                        logger.warning(f"è§£æå¸–å­å¤±è´¥: {e}")
                        continue
                
                if posts:
                    logger.info(f"æˆåŠŸä» {url} è·å– {len(posts)} æ¡å¸–å­")
                    break
                    
            except Exception as e:
                logger.warning(f"ä» {url} è·å–å¤±è´¥: {e}")
                continue
        
        if not posts:
            logger.error("æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥")
        
        return posts[:limit]
    
    def analyze_post(self, post: TruthPost) -> TruthPost:
        """
        åˆ†æå¸–å­å†…å®¹
        
        Args:
            post: å¸–å­å¯¹è±¡
            
        Returns:
            åˆ†æåçš„å¸–å­å¯¹è±¡
        """
        content = post.content
        
        # 1. ç®€å•æƒ…æ„Ÿåˆ†æï¼ˆåŸºäºå…³é”®è¯ï¼‰
        positive_words = ['great', 'good', 'excellent', 'amazing', 'fantastic', 'wonderful', 'best', 'win', 'winning', 'success', 'successful', 'love', 'like', 'happy', 'congratulations', 'thank', 'thanks']
        negative_words = ['bad', 'terrible', 'awful', 'worst', 'fail', 'failure', 'hate', 'dislike', 'sad', 'angry', 'disappointed', 'wrong', 'fake', 'lie', 'lies', 'stupid', 'dumb']
        
        content_lower = content.lower()
        pos_count = sum(1 for word in positive_words if word in content_lower)
        neg_count = sum(1 for word in negative_words if word in content_lower)
        
        if pos_count > neg_count:
            post.sentiment_score = min(0.5 + (pos_count - neg_count) * 0.1, 1.0)
            post.sentiment_label = "positive"
        elif neg_count > pos_count:
            post.sentiment_score = max(-0.5 - (neg_count - pos_count) * 0.1, -1.0)
            post.sentiment_label = "negative"
        else:
            post.sentiment_score = 0.0
            post.sentiment_label = "neutral"
        
        # 2. æå–è‚¡ç¥¨ä»£ç 
        matches = STOCK_PATTERN.findall(content)
        post.mentioned_stocks = list(set(matches))  # å»é‡
        
        # 3. æå–å…³é”®è¯ (ç®€å•ç‰ˆ)
        words = content.split()
        post.keywords = [w for w in words if len(w) > 4 and w.isalpha()][:10]
        
        return post
    
    def save_post(self, post: TruthPost) -> bool:
        """
        ä¿å­˜å¸–å­åˆ°æ•°æ®åº“
        
        Args:
            post: å¸–å­å¯¹è±¡
            
        Returns:
            æ˜¯å¦ä¸ºæ–°å¸–å­
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute('''
                INSERT OR IGNORE INTO posts (
                    id, created_at, content, url, media_urls,
                    replies_count, reblogs_count, favourites_count,
                    sentiment_score, sentiment_label, mentioned_stocks, keywords
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                post.id,
                post.created_at,
                post.content,
                post.url,
                json.dumps(post.media_urls),
                post.replies_count,
                post.reblogs_count,
                post.favourites_count,
                post.sentiment_score,
                post.sentiment_label,
                json.dumps(post.mentioned_stocks),
                json.dumps(post.keywords)
            ))
            
            is_new = cursor.rowcount > 0
            conn.commit()
            
            if is_new:
                logger.info(f"æ–°å¸–å­å·²ä¿å­˜: {post.id[:20]}...")
            
            return is_new
            
        except Exception as e:
            logger.error(f"ä¿å­˜å¸–å­å¤±è´¥: {e}")
            return False
            
        finally:
            conn.close()
    
    def get_new_posts(self, username: str = TRUMP_USERNAME) -> List[TruthPost]:
        """
        è·å–æ–°å¸–å­ï¼ˆæ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„ï¼‰
        
        Returns:
            æ–°å¸–å­åˆ—è¡¨
        """
        # è·å–æœ€æ–°å¸–å­
        posts = self.fetch_posts(username)
        
        new_posts = []
        for post in posts:
            # åˆ†æå¸–å­
            post = self.analyze_post(post)
            
            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœæ˜¯æ–°å¸–å­ï¼‰
            if self.save_post(post):
                new_posts.append(post)
        
        return new_posts
    
    def get_posts_with_stock_mentions(self, stock_code: str = None) -> List[Dict]:
        """
        è·å–æåŠè‚¡ç¥¨çš„å¸–å­
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¯é€‰ï¼Œä¸ºç©ºåˆ™è¿”å›æ‰€æœ‰æåŠè‚¡ç¥¨çš„å¸–å­ï¼‰
            
        Returns:
            å¸–å­åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            if stock_code:
                cursor.execute('''
                    SELECT * FROM posts 
                    WHERE mentioned_stocks LIKE ?
                    ORDER BY created_at DESC
                ''', (f'%"{stock_code}"%',))
            else:
                cursor.execute('''
                    SELECT * FROM posts 
                    WHERE mentioned_stocks != "[]"
                    ORDER BY created_at DESC
                ''')
            
            rows = cursor.fetchall()
            
            posts = []
            for row in rows:
                post = {
                    'id': row[0],
                    'created_at': row[1],
                    'content': row[2],
                    'url': row[3],
                    'media_urls': json.loads(row[4]) if row[4] else [],
                    'replies_count': row[5],
                    'reblogs_count': row[6],
                    'favourites_count': row[7],
                    'sentiment_score': row[8],
                    'sentiment_label': row[9],
                    'mentioned_stocks': json.loads(row[10]) if row[10] else [],
                    'keywords': json.loads(row[11]) if row[11] else [],
                }
                posts.append(post)
            
            return posts
            
        finally:
            conn.close()
    
    def generate_report(self, hours: int = 24) -> str:
        """
        ç”ŸæˆæŠ¥å‘Š
        
        Args:
            hours: æœ€è¿‘å¤šå°‘å°æ—¶
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        since = (datetime.now() - timedelta(hours=hours)).isoformat()
        
        cursor.execute('''
            SELECT * FROM posts 
            WHERE fetched_at > ?
            ORDER BY created_at DESC
        ''', (since,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return f"è¿‡å» {hours} å°æ—¶æ²¡æœ‰æ–°å¸–å­"
        
        lines = []
        lines.append(f"\nğŸ“Š Truth Social æŠ¥å‘Š (è¿‡å» {hours} å°æ—¶)")
        lines.append("=" * 60)
        lines.append(f"æ–°å¸–å­æ•°: {len(rows)}")
        
        # ç»Ÿè®¡æåŠè‚¡ç¥¨
        all_stocks = []
        for row in rows:
            stocks = json.loads(row[10]) if row[10] else []
            all_stocks.extend(stocks)
        
        if all_stocks:
            lines.append(f"\nğŸ“ˆ æåŠè‚¡ç¥¨: {', '.join(set(all_stocks))}")
        
        # æœ€æ–°å¸–å­
        lines.append("\nğŸ“ æœ€æ–°å¸–å­:")
        for row in rows[:5]:
            content = row[2][:100] + "..." if len(row[2]) > 100 else row[2]
            sentiment = row[9]
            emoji = "ğŸ˜Š" if sentiment == "positive" else "ğŸ˜ " if sentiment == "negative" else "ğŸ˜"
            lines.append(f"\n{emoji} {content}")
            lines.append(f"   ğŸ”— {row[3]}")
        
        return "\n".join(lines)


def run_daemon_mode(tracker: TruthSocialTracker, interval: int = 900):
    """
    å®ˆæŠ¤æ¨¡å¼è¿è¡Œ
    
    Args:
        tracker: è¿½è¸ªå™¨å®ä¾‹
        interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤15åˆ†é’Ÿ
    """
    logger.info(f"å¯åŠ¨å®ˆæŠ¤æ¨¡å¼ï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’")
    
    while True:
        try:
            logger.info("æ£€æŸ¥æ–°å¸–å­...")
            new_posts = tracker.get_new_posts()
            
            if new_posts:
                logger.info(f"å‘ç° {len(new_posts)} æ¡æ–°å¸–å­")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æåŠè‚¡ç¥¨çš„å¸–å­
                for post in new_posts:
                    if post.mentioned_stocks:
                        logger.info(f"ğŸš¨ å¸–å­æåŠè‚¡ç¥¨: {post.mentioned_stocks}")
                        logger.info(f"   å†…å®¹: {post.content[:100]}...")
                        # è¿™é‡Œå¯ä»¥è§¦å‘è‚¡ç¥¨åˆ†æ
            else:
                logger.info("æ²¡æœ‰æ–°å¸–å­")
            
            logger.info(f"ä¸‹æ¬¡æ£€æŸ¥: {interval}ç§’å")
            time.sleep(interval)
            
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºå®ˆæŠ¤æ¨¡å¼")
            break
        except Exception as e:
            logger.error(f"å®ˆæŠ¤æ¨¡å¼é”™è¯¯: {e}")
            time.sleep(60)  # å‡ºé”™å1åˆ†é’Ÿå†è¯•


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='Truth Social Tracker - Trump å¸–å­è¿½è¸ªå™¨'
    )
    
    parser.add_argument(
        '--daemon', '-d',
        action='store_true',
        help='å®ˆæŠ¤æ¨¡å¼ï¼ŒæŒç»­ç›‘æ§'
    )
    
    parser.add_argument(
        '--interval',
        type=int,
        default=900,
        help='æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤900ç§’ï¼ˆ15åˆ†é’Ÿï¼‰'
    )
    
    parser.add_argument(
        '--report',
        action='store_true',
        help='ç”ŸæˆæŠ¥å‘Š'
    )
    
    parser.add_argument(
        '--hours',
        type=int,
        default=24,
        help='æŠ¥å‘Šæ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰ï¼Œé»˜è®¤24å°æ—¶'
    )
    
    parser.add_argument(
        '--stock',
        type=str,
        help='æŸ¥è¯¢æåŠç‰¹å®šè‚¡ç¥¨çš„å¸–å­'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¿½è¸ªå™¨
    tracker = TruthSocialTracker()
    
    if args.daemon:
        # å®ˆæŠ¤æ¨¡å¼
        run_daemon_mode(tracker, args.interval)
        
    elif args.report:
        # ç”ŸæˆæŠ¥å‘Š
        report = tracker.generate_report(args.hours)
        print(report)
        
    elif args.stock:
        # æŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨
        posts = tracker.get_posts_with_stock_mentions(args.stock)
        print(f"\nğŸ“ˆ æåŠ {args.stock} çš„å¸–å­ ({len(posts)}æ¡):")
        for post in posts:
            print(f"\n{post['created_at']}")
            print(f"{post['content'][:200]}...")
            print(f"ğŸ”— {post['url']}")
            
    else:
        # å•æ¬¡è¿è¡Œ
        logger.info("å•æ¬¡è¿è¡Œæ¨¡å¼")
        new_posts = tracker.get_new_posts()
        
        if new_posts:
            print(f"\nâœ… è·å–åˆ° {len(new_posts)} æ¡æ–°å¸–å­")
            for post in new_posts:
                print(f"\nğŸ“… {post.created_at}")
                print(f"ğŸ“ {post.content[:150]}...")
                print(f"ğŸ˜Š æƒ…æ„Ÿ: {post.sentiment_label} ({post.sentiment_score:+.2f})")
                if post.mentioned_stocks:
                    print(f"ğŸ“ˆ æåŠè‚¡ç¥¨: {', '.join(post.mentioned_stocks)}")
                print(f"ğŸ”— {post.url}")
        else:
            print("\nâ„¹ï¸ æ²¡æœ‰æ–°å¸–å­")


if __name__ == "__main__":
    main()
